# Folder Structure for Evaluation Flow

```
evaluation-flow/
├── .promptflow/
├── methods/
│   └── judge_component.py
├── resource/
│   ├── config_predev.cfg
│   └── ssrai_config.cfg
├── convert_pdf_to_image.py
├── file_extracts_from_images.py
├── flow.dag.yaml
├── flow.tools.json
├── load_file_blob.py
├── llm_as_judge.py
├── requirements.txt
```

> Replace `original_qa_generation.py` and `question_prompts.py` with your evaluation-specific scripts, such as `llm_as_judge.py`.

### To Match QA Flow Style:
If your structure must exactly match `data-curation-flow-original-qa-generation-v1`, create a folder `evaluation-flow-llm-judging-v1` under `promptflow`, like so:

```
promptflow/
└── evaluation-flow-llm-judging-v1/
    ├── .promptflow/
    ├── methods/
    ├── resource/
    ├── convert_pdf_to_image.py
    ├── file_extracts_from_images.py
    ├── flow.dag.yaml
    ├── flow.tools.json
    ├── load_file_blob.py
    ├── llm_as_judge.py
    ├── requirements.txt
```

### ✅ flow.tools.json
```json
{
  "tools": [
    {
      "name": "llm_as_judge",
      "type": "python",
      "path": "llm_as_judge.py",
      "description": "LLM-based evaluator that compares generated answers with ground truth answers and scores them using SSRAIClient and judge_component."
    },
    {
      "name": "load_file_blob",
      "type": "python",
      "path": "load_file_blob.py",
      "description": "Loads input files from Azure Blob Storage."
    },
    {
      "name": "convert_pdf_to_image",
      "type": "python",
      "path": "convert_pdf_to_image.py",
      "description": "Converts uploaded PDF documents to images for OCR-based extraction."
    },
    {
      "name": "file_extracts_from_images",
      "type": "python",
      "path": "file_extracts_from_images.py",
      "description": "Extracts content from images converted from PDF pages."
    }
  ]
}
```

Would you like zipped source files now?

