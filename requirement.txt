from fts_commons.models.evaluation_models import EvalConfig
from fts_mgmt.models.response_models import EvaluationResponse
import logging

logger = logging.getLogger(__name__)

async def get_all_evaluation_strategies(self, limit: int, offset: int):
    try:
        items, total = self.evaluation_dao.get_all_evaluation_strategies(limit, offset)

        if not items:
            raise Exception("No Evaluation Strategy records found.")

        response = {
            "items": [],
            "count": total,
            "limit": limit,
            "offset": offset
        }

        for i in items:
            config_obj = None

            if isinstance(i.config, dict) and "static" in i.config and "dynamic" in i.config:
                try:
                    config_obj = EvalConfig(**i.config)
                except Exception as config_err:
                    logger.warning(f"Invalid config for strategy ID {i.id}: {config_err}")
                    config_obj = None
            else:
                logger.warning(f"Missing required config fields for strategy ID {i.id}: {i.config}")

            strategy_response = EvaluationResponse(
                evalStrategyId=i.id,
                evalStrategyName=i.name,
                evalStrategydescription=i.description,
                evalstrategyConfig=config_obj,
                createdBy=i.created_by,
                modifiedBy=i.modified_by,
                createdTs=i.created_ts,
                modifiedTs=i.modified_ts
            )

            response["items"].append(strategy_response)

        return response

    except Exception as e:
        logger.error(f"Exception in getting all evaluation strategies: {e}", exc_info=True)
        raise Exception(str(e))

