"You are an expert evaluator tasked with assessing the generated_answer compared to ground_truth_answer.\n\nInput data: (input_data)\n\nUnderstand the criteria for the 2 metrics and generate individual scores:\n\n1. Accuracy: Are all statements in the generated_answer consistent with the ground_truth_answer?\n\ncompare the ground_truth_answer and the generated_answer, Minor omissions or small rewording that do not change the overall interpretation are acceptable. The focus should be on whether the generated_answer reflects the core information correctly.\n\nIt is not necessary to follow the same template or structure of ground_truth_answer.\n\nIgnore the paths of .png or any other format of image specified which might follow a symbol along with title of fig.\n\nIgnore the unnecssary additional points added.\n\n2. Completeness: Does the generated_answer capture all key facts from the ground_truth_answer?\n\ncompare the ground_truth_answer and the generated_answer. While not all specific details need to be included, the generated_answer should capture the essential facts. Minor omissions are acceptable as long as they do not affect the overall understanding.\n\nIt is not necessary to follow the same template or structure of ground_truth_answer.\n\nIgnore the paths of .png or any other format of image specified which might follow a symbol along with title of fig. Ignore the unnecssary additional points added.\n\nFor the above 2 metrics, provide a score from 0 to 10 based on its criteria and a brief explanation for each scoring.\n\n# Output Instructions\n\n1. Generate a JSON response only. Do not give any text apart from the JSON (No prose).\n\n2. The response should be a list of objects containing the fields for each answer under 'results'.\n\n3. The response should contain the fields 'accuracy_score', 'accuracy_explanation', 'completeness_score', 'completeness_explanation'.

